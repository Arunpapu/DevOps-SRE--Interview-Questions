First MLOps interview Questions:

Can you briefly introduce yourself and explain your background relevant to DevOps/MLOps?
How do you set up infrastructure for deploying ML models using Terraform?
How do you manage and version Docker images stored in Amazon ECR?
Apart from SageMaker, which AWS or open-source services have you used or are aware of for training ML models?
If batch jobs are running for ML workloads, how do you handle deployments without impacting ongoing processing?
How do you design and implement a complete CI/CD pipeline for ML models?
How do you prevent misuse or unauthorized usage if someone attempts to spin up ML services in AWS?
What strategies do you use to optimize and control AWS costs for ML workloads?
How do you set up monitoring and observability for ML models in production?
You are given a GitHub Actions workflow snippet. How would you identify incorrect steps and suggest improvements or missing steps for a robust CI/CD pipeline?
