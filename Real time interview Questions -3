Docker:
I can able to get access application from outside container but from inside getting packet loss. How do you trobleshoot. ( Issue related to container networking , firewall rules, DNS)
How do you get logs from docker level.
Two containers are there. One with front end application and second container has db.Fisrt I want to start db then front end. What should you do?( 2tier application)

Kubernetes:
How do you call pod1 to pod2 without service.
2.what is Container Network Interface
3.what is CSI driver
4.Static volume provisioning and dynamic volume provisioning. Explain in with use case.
5.what is auto volume expansion.

what is land job activity in migration
2.what type of basic azure services u will consider 
4.Hub and Spoke topology 
5.day to day actives what type of work ur doing is it a support/project 
6.what type of pipelines ur handling basically it means QA ,UAT 
7. how many team members are there?
8. How about the deployment , IAAS model or Saas  model
9.pick one requirement and u deployed end to end by using azure services 
10. suppose there is a dotnet application which is basically a 3 -tier application ,for webapi deploymment i hvae used azure appservices, for background jobs i have used function apps ,and for messaging i have used servicebus and how about the connectivity to all thses?
11.how on-premisis user has to access the application/access the code which was deployed in cloud service . how my connectivity will be configured ( on-premiss to cloud )
12.IN general as azure specalist from ur side what is ur recomendation is it a sit-to-site vpn or Expressroute
13.lets assume consider banking sector only i dont have that much budget but since ur telling that for low budget go for site-to-site-vpn but on otherside ur saying that express-route is more secure > So how cn u justy that, because banking costumer has a limitation for him
14.IN which senario we will go for site-to-site vpn  and Expressroute 
15.any storage related components have u worked on?
16. lets say i have a condition i need to access the data which is stored in storage account but that is huge data which is comming from enduser perspective lets say some cppotency that is recording 24/7 and data will be stored but at the same time if anyone comes and to retrieve the data obviously they will get it from storage account,now i need to implement some cost optimisation techniques on storage account to reduce cose because data to be incresed daytoday ?whta afre the possible ways 
with respective storageaccount
16.suppose u have created a storage accouunt with hot-tier is it possible to change to cool-tier
17. manually we can change from hottier to cool tier ,but when i have huge data it will take time right .
18.Did u face  any challenges while ur taking backup? any issues 
19. what type of services ur have used for backup .is it azure specific or any on-premisis
20.what are the senarios u configured for DR?
21.how about the monitoring techniques like any alerts we can 
22.lets assume we got an requirement that we have a production infra running on azure cloud and we need to setup an alert mechanism where there some thresold values given by customers but considering huge infra but ur getting hundreds of alerts ,in that alert how can u segregate  that we need to findout ,which alert we need to proporitise ,any appriach u have ?

23.Any known issues u encountered any pipeline is integrated/ any production code is ur pushing or production any known issue and tell which is critical and how u got resolved 

24. Have u done any migration form on-premis to azure / from azure to azure with any scenarion and what shot of migrarion s it resource migration or data migration 
25.what are the prechecks u have to consider before migration
